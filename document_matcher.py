#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ú–æ–¥—É–ª—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∑–∞—è–≤–∫–∞–º–∏ –Ω–∞ –ø–µ—Ä–µ–≤–æ–∑–∫—É.

–†–µ–∞–ª–∏–∑—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, –∫ –∫–∞–∫–æ–π –∑–∞—è–≤–∫–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
–Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤: –≥–æ—Å–Ω–æ–º–µ—Ä –¢–°, –ø—Ä–∏—Ü–µ–ø, –≤–æ–¥–∏—Ç–µ–ª—å, –¥–∞—Ç—ã, –Ω–æ–º–µ—Ä–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ü—Ä–∞–≤–∏–ª–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞:
1. –¢–° + –ø—Ä–∏—Ü–µ–ø + –¥–∞—Ç–∞ (high confidence)
2. –¢–° + –¥–∞—Ç–∞ (high confidence)
3. –í–æ–¥–∏—Ç–µ–ª—å + –¥–∞—Ç–∞ (high confidence)
4. –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –ø–∞–∫–µ—Ç–µ (medium confidence)
5. –ü–∞–∫–µ—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞ - —Å–æ—Å–µ–¥—Å—Ç–≤–æ —Å —è–∫–æ—Ä–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º (low confidence)
6. –î–∞—Ç–∞ + –≤—Ç–æ—Ä–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (low confidence)
"""

import logging
import os
import re
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

import pdfplumber

logger = logging.getLogger(__name__)


# =============================================================================
# –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏—è –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
# =============================================================================

class DocumentType(Enum):
    """–¢–∏–ø—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≥—Ä—É–∑–æ–ø–µ—Ä–µ–≤–æ–∑–∫–∏."""
    TRANSPORT_WAYBILL = "transport_waybill"  # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è –Ω–∞–∫–ª–∞–¥–Ω–∞—è (–¢–ù/–¢—Ä–ù)
    CARGO_WAYBILL = "cargo_waybill"  # –¢–æ–≤–∞—Ä–Ω–æ-—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è –Ω–∞–∫–ª–∞–¥–Ω–∞—è (–¢–¢–ù)
    TORG12 = "torg12"  # –¢–æ–≤–∞—Ä–Ω–∞—è –Ω–∞–∫–ª–∞–¥–Ω–∞—è –¢–û–†–ì-12
    EXPEDITOR_RECEIPT = "expeditor_receipt"  # –≠–∫—Å–ø–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è —Ä–∞—Å–ø–∏—Å–∫–∞
    IDLE_SHEET = "idle_sheet"  # –õ–∏—Å—Ç –ø—Ä–æ—Å—Ç–æ—è
    ACT = "act"  # –ê–∫—Ç (–ø—Ä–∏–µ–º–∞, –ø—Ä–æ—Å—Ç–æ—è, –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç)
    REGISTRY = "registry"  # –†–µ–µ—Å—Ç—Ä —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    APPENDIX = "appendix"  # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∫ –Ω–∞–∫–ª–∞–¥–Ω–æ–π
    INVOICE = "invoice"  # –°—á—ë—Ç-—Ñ–∞–∫—Ç—É—Ä–∞
    UPD = "upd"  # –£–ü–î
    POWER_OF_ATTORNEY = "power_of_attorney"  # –î–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    OTHER = "other"  # –ò–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    UNKNOWN = "unknown"  # –ù–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω


class ConfidenceLevel(Enum):
    """–£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏."""
    HIGH = "high"  # –¢–°+–ø—Ä–∏—Ü–µ–ø+–¥–∞—Ç–∞, –¢–°+–¥–∞—Ç–∞, –≤–æ–¥–∏—Ç–µ–ª—å+–¥–∞—Ç–∞
    MEDIUM = "medium"  # –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞, –¥–∞—Ç–∞+–≤—Ç–æ—Ä–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    LOW = "low"  # –¢–æ–ª—å–∫–æ –ø–∞–∫–µ—Ç/—Å–æ—Å–µ–¥—Å—Ç–≤–æ


class MatchReason(Enum):
    """–û—Å–Ω–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–≤—è–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∫ –∑–∞—è–≤–∫–µ."""
    VEHICLE_TRAILER_DATE = "vehicle_trailer_date"  # –¢–° + –ø—Ä–∏—Ü–µ–ø + –¥–∞—Ç–∞
    VEHICLE_DATE = "vehicle_date"  # –¢–° + –¥–∞—Ç–∞
    DRIVER_DATE = "driver_date"  # –í–æ–¥–∏—Ç–µ–ª—å + –¥–∞—Ç–∞
    DOCUMENT_NUMBER = "document_number"  # –ù–æ–º–µ—Ä –ø–µ—Ä–µ–≤–æ–∑–æ—á–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    PACKAGE = "package"  # –ü–∞–∫–µ—Ç (–º–µ–∂–¥—É —è–∫–æ—Ä–Ω—ã–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏)
    DATE_SECONDARY = "date_secondary"  # –î–∞—Ç–∞ + –≤—Ç–æ—Ä–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    MANUAL = "manual"  # –†—É—á–Ω–æ–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ
    UNMATCHED = "unmatched"  # –ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω


# –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∑–∞–≥–æ–ª–æ–≤–∫–∏)
DOCUMENT_TYPE_PATTERNS = {
    DocumentType.TRANSPORT_WAYBILL: [
        r'—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è\s+–Ω–∞–∫–ª–∞–¥–Ω–∞—è',
        r'–¢—Ä–ù\s*‚Ññ',
        r'–¢–ù\s*‚Ññ',
    ],
    DocumentType.CARGO_WAYBILL: [
        r'—Ç–æ–≤–∞—Ä–Ω–æ[\s\-]*—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è\s+–Ω–∞–∫–ª–∞–¥–Ω–∞—è',
        r'–¢–¢–ù\s*‚Ññ',
    ],
    DocumentType.TORG12: [
        r'—Ç–æ—Ä–≥[\s\-]*12',
        r'—Ç–æ–≤–∞—Ä–Ω–∞—è\s+–Ω–∞–∫–ª–∞–¥–Ω–∞—è',
        r'—É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è\s+—Ñ–æ—Ä–º–∞\s+‚Ññ\s*—Ç–æ—Ä–≥',
    ],
    DocumentType.EXPEDITOR_RECEIPT: [
        r'—ç–∫—Å–ø–µ–¥–∏—Ç–æ—Ä—Å–∫–∞—è\s+—Ä–∞—Å–ø–∏—Å–∫–∞',
    ],
    DocumentType.IDLE_SHEET: [
        r'–ª–∏—Å—Ç\s+–ø—Ä–æ—Å—Ç–æ—è',
        r'–∞–∫—Ç\s+–ø—Ä–æ—Å—Ç–æ—è',
    ],
    DocumentType.ACT: [
        r'–∞–∫—Ç\s+(?:–ø—Ä–∏–µ–º–∞|–ø—Ä–∏—ë–º–∞|–≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö|—Å–≤–µ—Ä–∫–∏|–æ–±\s+–æ–∫–∞–∑–∞–Ω–∏–∏)',
    ],
    DocumentType.REGISTRY: [
        r'—Ä–µ–µ—Å—Ç—Ä\s+(?:—Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö|–¥–æ–∫—É–º–µ–Ω—Ç–æ–≤|–Ω–∞–∫–ª–∞–¥–Ω—ã—Ö)',
    ],
    DocumentType.APPENDIX: [
        r'–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ\s*‚Ññ?\s*\d*\s*–∫\s+(?:—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–π|—Ç–æ–≤–∞—Ä–Ω–æ–π)',
        r'–ø–µ—Ä–µ—á–µ–Ω—å\s+.*–∫\s+(?:—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–π|—Ç–æ–≤–∞—Ä–Ω–æ–π)',
    ],
    DocumentType.INVOICE: [
        r'—Å—á—ë—Ç[\s\-]*—Ñ–∞–∫—Ç—É—Ä–∞',
        r'—Å—á–µ—Ç[\s\-]*—Ñ–∞–∫—Ç—É—Ä–∞',
    ],
    DocumentType.UPD: [
        r'—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π\s+–ø–µ—Ä–µ–¥–∞—Ç–æ—á–Ω—ã–π\s+–¥–æ–∫—É–º–µ–Ω—Ç',
        r'–£–ü–î\s*‚Ññ',
    ],
    DocumentType.POWER_OF_ATTORNEY: [
        r'–¥–æ–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å',
    ],
}

# –ü–∞—Ç—Ç–µ—Ä–Ω –≥–æ—Å–Ω–æ–º–µ—Ä–∞ –†–§ (—Å —É—á—ë—Ç–æ–º —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤)
# –§–æ—Ä–º–∞—Ç: –ê123–ë–í77 –∏–ª–∏ –ê 123 –ë–í 77 –∏–ª–∏ A123BC77 (–ª–∞—Ç–∏–Ω–∏—Ü–∞)
VEHICLE_PLATE_PATTERN = re.compile(
    r'[–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•ABEKMHOPCTYX]\s*'
    r'(\d{3})\s*'
    r'[–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•ABEKMHOPCTYX]{2}\s*'
    r'(\d{2,3})',
    re.IGNORECASE
)

# –ü–∞—Ç—Ç–µ—Ä–Ω –ø—Ä–∏—Ü–µ–ø–∞ (—Ñ–æ—Ä–º–∞—Ç: –ê–í1234-77 –∏–ª–∏ –ê–í 1234 77)
TRAILER_PLATE_PATTERN = re.compile(
    r'[–ê–í–ï–ö–ú–ù–û–†–°–¢–£–•ABEKMHOPCTYX]{2}\s*'
    r'(\d{4,6})\s*'
    r'[\-\s]?(\d{2,3})',
    re.IGNORECASE
)

# –ü–∞—Ç—Ç–µ—Ä–Ω –¥–∞—Ç—ã
DATE_PATTERNS = [
    r'(\d{1,2})[./](\d{1,2})[./](\d{4})',  # DD.MM.YYYY –∏–ª–∏ DD/MM/YYYY
    r'(\d{1,2})[./](\d{1,2})[./](\d{2})\b',  # DD.MM.YY
    r'(\d{1,2})\s+(?:—è–Ω–≤–∞—Ä—è|—Ñ–µ–≤—Ä–∞–ª—è|–º–∞—Ä—Ç–∞|–∞–ø—Ä–µ–ª—è|–º–∞—è|–∏—é–Ω—è|–∏—é–ª—è|–∞–≤–≥—É—Å—Ç–∞|—Å–µ–Ω—Ç—è–±—Ä—è|–æ–∫—Ç—è–±—Ä—è|–Ω–æ—è–±—Ä—è|–¥–µ–∫–∞–±—Ä—è)\s+(\d{4})',
]

MONTH_NAMES = {
    '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
    '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
    '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12
}


# =============================================================================
# –ö–ª–∞—Å—Å—ã –¥–∞–Ω–Ω—ã—Ö
# =============================================================================

@dataclass
class DocumentIdentifiers:
    """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    # –ü–µ—Ä–≤—ã–π —É—Ä–æ–≤–µ–Ω—å (—Å–∏–ª—å–Ω—ã–µ)
    vehicle_plate: str = ""  # –ì–æ—Å–Ω–æ–º–µ—Ä —Ç—è–≥–∞—á–∞
    trailer_plate: str = ""  # –ì–æ—Å–Ω–æ–º–µ—Ä –ø—Ä–∏—Ü–µ–ø–∞
    driver_name: str = ""  # –§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è
    document_number: str = ""  # –ù–æ–º–µ—Ä –¢–ù/–¢–¢–ù/–∑–∞–∫–∞–∑–∞
    document_date: str = ""  # –î–∞—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞

    # –í—Ç–æ—Ä–æ–π —É—Ä–æ–≤–µ–Ω—å (–≤—Ç–æ—Ä–∏—á–Ω—ã–µ)
    loading_address: str = ""  # –ê–¥—Ä–µ—Å –ø–æ–≥—Ä—É–∑–∫–∏
    unloading_address: str = ""  # –ê–¥—Ä–µ—Å –≤—ã–≥—Ä—É–∑–∫–∏
    shipper_name: str = ""  # –ì—Ä—É–∑–æ–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å
    consignee_name: str = ""  # –ì—Ä—É–∑–æ–ø–æ–ª—É—á–∞—Ç–µ–ª—å
    order_number: str = ""  # –ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏/–∑–∞–∫–∞–∑–∞
    amount: float = 0.0  # –°—É–º–º–∞


@dataclass
class ParsedDocument:
    """–†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ PDF."""
    doc_type: DocumentType = DocumentType.UNKNOWN
    page_start: int = 0  # –ù–∞—á–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ (1-based)
    page_end: int = 0  # –ö–æ–Ω–µ—á–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ (1-based)
    identifiers: DocumentIdentifiers = field(default_factory=DocumentIdentifiers)
    raw_text: str = ""  # –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
    source_file: str = ""  # –ò–º—è —Ñ–∞–π–ª–∞-–∏—Å—Ç–æ—á–Ω–∏–∫–∞

    @property
    def page_range(self) -> str:
        """–î–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–∞–Ω–∏—Ü –≤ —á–∏—Ç–∞–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ."""
        if self.page_start == self.page_end:
            return f"—Å—Ç—Ä. {self.page_start}"
        return f"—Å—Ç—Ä. {self.page_start}-{self.page_end}"


@dataclass
class ApplicationInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞—è–≤–∫–µ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è."""
    number: str = ""  # –ù–æ–º–µ—Ä –∑–∞—è–≤–∫–∏ (–°–ü...)
    date: str = ""  # –î–∞—Ç–∞ –∑–∞—è–≤–∫–∏
    vehicle_plate: str = ""  # –ì–æ—Å–Ω–æ–º–µ—Ä —Ç—è–≥–∞—á–∞
    trailer_plate: str = ""  # –ì–æ—Å–Ω–æ–º–µ—Ä –ø—Ä–∏—Ü–µ–ø–∞
    driver_name: str = ""  # –§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è
    load_date: str = ""  # –î–∞—Ç–∞ –ø–æ–≥—Ä—É–∑–∫–∏
    unload_date: str = ""  # –î–∞—Ç–∞ —Ä–∞–∑–≥—Ä—É–∑–∫–∏
    route: str = ""  # –ú–∞—Ä—à—Ä—É—Ç
    amount: float = 0.0  # –°—É–º–º–∞


@dataclass
class MatchResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –∑–∞—è–≤–∫–æ–π."""
    document: ParsedDocument
    application: Optional[ApplicationInfo] = None
    confidence: ConfidenceLevel = ConfidenceLevel.LOW
    reason: MatchReason = MatchReason.UNMATCHED
    reason_details: str = ""  # –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –≤–Ω—É—Ç—Ä–∏ –ø–∞–∫–µ—Ç–∞")

    @property
    def is_matched(self) -> bool:
        return self.application is not None


@dataclass
class MatchingReport:
    """–ü–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç –æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
    source_file: str = ""
    total_pages: int = 0
    documents: List[ParsedDocument] = field(default_factory=list)
    results: List[MatchResult] = field(default_factory=list)
    unmatched_documents: List[ParsedDocument] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)


# =============================================================================
# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
# =============================================================================

def normalize_vehicle_plate(plate: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≥–æ—Å–Ω–æ–º–µ—Ä –¢–°.

    –ü—Ä–∏–≤–æ–¥–∏—Ç –∫ —Ñ–æ—Ä–º–∞—Ç—É: –ê123–ë–í77 (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤, –∫–∏—Ä–∏–ª–ª–∏—Ü–∞ –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
    """
    if not plate:
        return ""

    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã, –ø–µ—Ä–µ–Ω–æ—Å—ã –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –≤–µ—Ä—Ö–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    plate = plate.upper().replace(" ", "").replace("-", "").replace("\n", "").replace("\r", "")

    # –ó–∞–º–µ–Ω—è–µ–º –ª–∞—Ç–∏–Ω–∏—Ü—É –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—É (–¥–ª—è —É–Ω–∏—Ñ–∏–∫–∞—Ü–∏–∏)
    lat_to_cyr = {
        'A': '–ê', 'B': '–í', 'E': '–ï', 'K': '–ö', 'M': '–ú',
        'H': '–ù', 'O': '–û', 'P': '–†', 'C': '–°', 'T': '–¢',
        'Y': '–£', 'X': '–•'
    }
    for lat, cyr in lat_to_cyr.items():
        plate = plate.replace(lat, cyr)

    return plate


def normalize_driver_name(name: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è.

    –ü—Ä–∏–≤–æ–¥–∏—Ç –∫ —Ñ–æ—Ä–º–∞—Ç—É: –§–∞–º–∏–ª–∏—è –ò–º—è –û—Ç—á–µ—Å—Ç–≤–æ (–∏–º–µ–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
    """
    if not name:
        return ""

    # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    name = name.replace("\n", " ").replace("\r", " ")

    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    name = " ".join(name.split())

    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ title case
    name = name.title()

    return name


def parse_date(text: str) -> Optional[datetime]:
    """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    if not text:
        return None

    # DD.MM.YYYY
    match = re.search(r'(\d{1,2})[./](\d{1,2})[./](\d{4})', text)
    if match:
        try:
            day, month, year = int(match.group(1)), int(match.group(2)), int(match.group(3))
            return datetime(year, month, day)
        except ValueError:
            pass

    # DD.MM.YY
    match = re.search(r'(\d{1,2})[./](\d{1,2})[./](\d{2})\b', text)
    if match:
        try:
            day, month, year = int(match.group(1)), int(match.group(2)), int(match.group(3))
            year = 2000 + year if year < 50 else 1900 + year
            return datetime(year, month, day)
        except ValueError:
            pass

    # "DD –º–µ—Å—è—Ü–∞ YYYY"
    for month_name, month_num in MONTH_NAMES.items():
        pattern = rf'(\d{{1,2}})\s+{month_name}\s+(\d{{4}})'
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            try:
                day, year = int(match.group(1)), int(match.group(2))
                return datetime(year, month_num, day)
            except ValueError:
                pass

    return None


def format_date(dt: Optional[datetime]) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–∞—Ç—É –≤ —Å—Ç—Ä–æ–∫—É DD.MM.YYYY."""
    if not dt:
        return ""
    return dt.strftime("%d.%m.%Y")


def dates_match(date1: str, date2: str, tolerance_days: int = 1) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–≤–ø–∞–¥–∞—é—Ç –ª–∏ –¥–∞—Ç—ã (—Å –¥–æ–ø—É—Å–∫–æ–º).

    Args:
        date1: –ü–µ—Ä–≤–∞—è –¥–∞—Ç–∞
        date2: –í—Ç–æ—Ä–∞—è –¥–∞—Ç–∞
        tolerance_days: –î–æ–ø—É—Å—Ç–∏–º–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ –¥–Ω—è—Ö
    """
    dt1 = parse_date(date1)
    dt2 = parse_date(date2)

    if not dt1 or not dt2:
        return False

    diff = abs((dt1 - dt2).days)
    return diff <= tolerance_days


def date_in_range(date: str, start_date: str, end_date: str, tolerance_days: int = 1) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–ø–∞–¥–∞–µ—Ç –ª–∏ –¥–∞—Ç–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω.

    Args:
        date: –ü—Ä–æ–≤–µ—Ä—è–µ–º–∞—è –¥–∞—Ç–∞
        start_date: –ù–∞—á–∞–ª–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        end_date: –ö–æ–Ω–µ—Ü –¥–∏–∞–ø–∞–∑–æ–Ω–∞
        tolerance_days: –î–æ–ø—É—Å–∫ –ø–æ –∫—Ä–∞—è–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞
    """
    dt = parse_date(date)
    dt_start = parse_date(start_date)
    dt_end = parse_date(end_date)

    if not dt:
        return False

    # –ï—Å–ª–∏ –Ω–µ—Ç –Ω–∞—á–∞–ª–∞/–∫–æ–Ω—Ü–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ –∏–º–µ—é—â–µ–π—Å—è –≥—Ä–∞–Ω–∏—Ü–µ
    if dt_start and dt_end:
        start = dt_start - timedelta(days=tolerance_days)
        end = dt_end + timedelta(days=tolerance_days)
        return start <= dt <= end
    elif dt_start:
        start = dt_start - timedelta(days=tolerance_days)
        return dt >= start
    elif dt_end:
        end = dt_end + timedelta(days=tolerance_days)
        return dt <= end

    return False


# =============================================================================
# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
# =============================================================================

def extract_vehicle_plates(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–æ—Å–Ω–æ–º–µ—Ä–∞ –¢–° –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    plates = []

    # –ò—â–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –≥–æ—Å–Ω–æ–º–µ—Ä–∞
    for match in VEHICLE_PLATE_PATTERN.finditer(text):
        plate = match.group(0)
        normalized = normalize_vehicle_plate(plate)
        if normalized and normalized not in plates:
            plates.append(normalized)

    return plates


def extract_trailer_plates(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä–∞ –ø—Ä–∏—Ü–µ–ø–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    plates = []

    # –ò—â–µ–º –Ω–æ–º–µ—Ä–∞ –ø—Ä–∏—Ü–µ–ø–æ–≤
    for match in TRAILER_PLATE_PATTERN.finditer(text):
        plate = match.group(0)
        normalized = normalize_vehicle_plate(plate)
        if normalized and normalized not in plates:
            plates.append(normalized)

    # –¢–∞–∫–∂–µ –∏—â–µ–º –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ —Å–ª–æ–≤–∞ "–ø—Ä–∏—Ü–µ–ø"
    trailer_context = re.findall(
        r'–ø—Ä–∏—Ü–µ–ø[–∞]?\s+([–ê-–ØA-Z]{2}\s*\d{4,6}\s*[\-\s]?\d{2,3})',
        text, re.IGNORECASE
    )
    for plate in trailer_context:
        normalized = normalize_vehicle_plate(plate)
        if normalized and normalized not in plates:
            plates.append(normalized)

    return plates


def extract_driver_name(text: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –§–ò–û –≤–æ–¥–∏—Ç–µ–ª—è –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–æ–¥–∏—Ç–µ–ª—è
    patterns = [
        r'–≤–æ–¥–∏—Ç–µ–ª—å[:\s]+([–ê-–Ø–Å–∞-—è—ë]+\s+[–ê-–Ø–Å–∞-—è—ë]+(?:\s+[–ê-–Ø–Å–∞-—è—ë]+)?)',
        r'–§–ò–û\s+–≤–æ–¥–∏—Ç–µ–ª[—è—å]?[:\s]+([–ê-–Ø–Å–∞-—è—ë]+\s+[–ê-–Ø–Å–∞-—è—ë]+(?:\s+[–ê-–Ø–Å–∞-—è—ë]+)?)',
        r'–ø—Ä–∏–Ω—è–ª[:\s]+([–ê-–Ø–Å–∞-—è—ë]+\s+[–ê-–Ø–Å–∞-—è—ë]+(?:\s+[–ê-–Ø–Å–∞-—è—ë]+)?)',
    ]

    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            name = match.group(1).strip()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –§–ò–û (–º–∏–Ω–∏–º—É–º 2 —Å–ª–æ–≤–∞)
            if len(name.split()) >= 2:
                return normalize_driver_name(name)

    return ""


def extract_document_number(text: str, doc_type: DocumentType) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
    patterns = []

    if doc_type in (DocumentType.TRANSPORT_WAYBILL, DocumentType.CARGO_WAYBILL):
        patterns = [
            r'(?:–¢–ù|–¢–¢–ù|–¢—Ä–ù|—Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–∞—è\s+–Ω–∞–∫–ª–∞–¥–Ω–∞—è)\s*‚Ññ\s*([A-Za-z0-9–ê-–Ø–∞-—è/\-]+)',
            r'–Ω–∞–∫–ª–∞–¥–Ω–∞—è\s*‚Ññ\s*([A-Za-z0-9–ê-–Ø–∞-—è/\-]+)',
        ]
    elif doc_type == DocumentType.TORG12:
        patterns = [
            r'(?:–¢–û–†–ì[\s\-]*12|—Ç–æ–≤–∞—Ä–Ω–∞—è\s+–Ω–∞–∫–ª–∞–¥–Ω–∞—è)\s*‚Ññ\s*([A-Za-z0-9–ê-–Ø–∞-—è/\-]+)',
        ]
    elif doc_type == DocumentType.IDLE_SHEET:
        patterns = [
            r'(?:–ª–∏—Å—Ç\s+–ø—Ä–æ—Å—Ç–æ—è|–∞–∫—Ç\s+–ø—Ä–æ—Å—Ç–æ—è)\s*‚Ññ\s*([A-Za-z0-9–ê-–Ø–∞-—è/\-]+)',
        ]
    else:
        patterns = [
            r'‚Ññ\s*([A-Za-z0-9–ê-–Ø–∞-—è/\-]+)',
        ]

    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return match.group(1).strip()

    return ""


def extract_dates(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –¥–∞—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞."""
    dates = []

    # DD.MM.YYYY
    for match in re.finditer(r'(\d{1,2})[./](\d{1,2})[./](\d{4})', text):
        date_str = f"{match.group(1).zfill(2)}.{match.group(2).zfill(2)}.{match.group(3)}"
        if date_str not in dates:
            dates.append(date_str)

    return dates


def extract_identifiers(text: str, doc_type: DocumentType) -> DocumentIdentifiers:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    """
    ids = DocumentIdentifiers()

    # –¢–°
    vehicles = extract_vehicle_plates(text)
    if vehicles:
        ids.vehicle_plate = vehicles[0]

    # –ü—Ä–∏—Ü–µ–ø
    trailers = extract_trailer_plates(text)
    if trailers:
        ids.trailer_plate = trailers[0]

    # –í–æ–¥–∏—Ç–µ–ª—å
    ids.driver_name = extract_driver_name(text)

    # –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞
    ids.document_number = extract_document_number(text, doc_type)

    # –î–∞—Ç—ã
    dates = extract_dates(text)
    if dates:
        ids.document_date = dates[0]

    # –ê–¥—Ä–µ—Å–∞ –ø–æ–≥—Ä—É–∑–∫–∏/–≤—ã–≥—Ä—É–∑–∫–∏
    loading_match = re.search(
        r'(?:–ø–æ–≥—Ä—É–∑–∫[–∞–∏]|–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∏[–µ—è]|–≥—Ä—É–∑–æ–æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª[—å—è])[:\s]+([^\n]{10,100})',
        text, re.IGNORECASE
    )
    if loading_match:
        ids.loading_address = loading_match.group(1).strip()[:100]

    unloading_match = re.search(
        r'(?:–≤—ã–≥—Ä—É–∑–∫[–∞–∏]|–¥–æ—Å—Ç–∞–≤–∫[–∞–∏]|–≥—Ä—É–∑–æ–ø–æ–ª—É—á–∞—Ç–µ–ª[—å—è])[:\s]+([^\n]{10,100})',
        text, re.IGNORECASE
    )
    if unloading_match:
        ids.unloading_address = unloading_match.group(1).strip()[:100]

    return ids


# =============================================================================
# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∏ –≥—Ä–∞–Ω–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
# =============================================================================

def detect_document_type(text: str) -> DocumentType:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ —Ç–µ–∫—Å—Ç—É."""
    text_lower = text.lower()

    for doc_type, patterns in DOCUMENT_TYPE_PATTERNS.items():
        for pattern in patterns:
            if re.search(pattern, text_lower):
                return doc_type

    return DocumentType.UNKNOWN


def is_continuation_page(text: str, prev_doc_type: DocumentType) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    """
    text_lower = text.lower()

    # –Ø–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
    continuation_patterns = [
        r'—Å—Ç—Ä\.?\s*\d+',  # –°—Ç—Ä. 2
        r'—Å—Ç—Ä–∞–Ω–∏—Ü–∞\s+\d+\s+–∏–∑',  # –°—Ç—Ä–∞–Ω–∏—Ü–∞ 2 –∏–∑ 5
        r'–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ',
        r'–ª–∏—Å—Ç\s+\d+',
    ]

    for pattern in continuation_patterns:
        if re.search(pattern, text_lower):
            return True

    # –ï—Å–ª–∏ —ç—Ç–æ –¢–û–†–ì-12 –∏ –µ—Å—Ç—å —Ç–∞–±–ª–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    if prev_doc_type == DocumentType.TORG12:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–∞–±–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ —Ñ–æ—Ä–º—ã
        has_table_data = bool(re.search(r'\d+\s+\d+[\.,]\d+', text))
        has_header = bool(re.search(r'—Ç–æ—Ä–≥[\s\-]*12|—Ç–æ–≤–∞—Ä–Ω–∞—è\s+–Ω–∞–∫–ª–∞–¥–Ω–∞—è', text_lower))
        if has_table_data and not has_header:
            return True

    return False


def detect_document_boundaries(pages: List[str]) -> List[Tuple[int, int, DocumentType]]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ —Å–ø–∏—Å–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü.

    Returns:
        List of (start_page, end_page, doc_type) - 1-based page numbers
    """
    boundaries = []
    current_start = 1
    current_type = DocumentType.UNKNOWN

    for i, page_text in enumerate(pages):
        page_num = i + 1
        detected_type = detect_document_type(page_text)

        if i == 0:
            # –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
            current_type = detected_type
            current_start = page_num
        elif detected_type != DocumentType.UNKNOWN:
            # –ù–∞–π–¥–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            if not is_continuation_page(page_text, current_type):
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
                boundaries.append((current_start, page_num - 1, current_type))
                current_start = page_num
                current_type = detected_type
        elif is_continuation_page(page_text, current_type):
            # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            pass
        else:
            # –ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            # –ï—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–π –Ω–æ–≤—ã–π –Ω–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –¥–∞—Ç–æ–π
            new_doc_match = re.search(
                r'‚Ññ\s*[A-Za-z0-9/\-]+\s+–æ—Ç\s+\d{1,2}[./]\d{1,2}[./]\d{2,4}',
                page_text
            )
            if new_doc_match and current_type != DocumentType.UNKNOWN:
                boundaries.append((current_start, page_num - 1, current_type))
                current_start = page_num
                current_type = detected_type

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
    if pages:
        boundaries.append((current_start, len(pages), current_type))

    return boundaries


# =============================================================================
# –ê–ª–≥–æ—Ä–∏—Ç–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
# =============================================================================

def match_by_vehicle_and_trailer(
    doc: ParsedDocument,
    applications: List[ApplicationInfo]
) -> Optional[Tuple[ApplicationInfo, ConfidenceLevel, str]]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å –∑–∞—è–≤–∫–æ–π –ø–æ –¢–° + –ø—Ä–∏—Ü–µ–ø + –¥–∞—Ç–∞.

    –ü—Ä–∞–≤–∏–ª–æ 3.1.A: –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç—è–≥–∞—á + –ø—Ä–∏—Ü–µ–ø —Å —Ä–µ—Å—É—Ä—Å–∞–º–∏ –∑–∞—è–≤–∫–∏
    –∏ –¥–∞—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –ø–µ—Ä–∏–æ–¥ –ø–µ—Ä–µ–≤–æ–∑–∫–∏.
    """
    if not doc.identifiers.vehicle_plate:
        return None

    doc_vehicle = normalize_vehicle_plate(doc.identifiers.vehicle_plate)
    doc_trailer = normalize_vehicle_plate(doc.identifiers.trailer_plate)
    doc_date = doc.identifiers.document_date

    for app in applications:
        app_vehicle = normalize_vehicle_plate(app.vehicle_plate)
        app_trailer = normalize_vehicle_plate(app.trailer_plate)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¢–°
        if doc_vehicle != app_vehicle:
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø—Ä–∏—Ü–µ–ø–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –æ–±–æ–∏—Ö)
        trailer_match = True
        if doc_trailer and app_trailer:
            trailer_match = doc_trailer == app_trailer

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É
        date_match = False
        if doc_date:
            if app.load_date and app.unload_date:
                date_match = date_in_range(doc_date, app.load_date, app.unload_date)
            elif app.load_date:
                date_match = dates_match(doc_date, app.load_date, tolerance_days=2)
            elif app.date:
                date_match = dates_match(doc_date, app.date, tolerance_days=5)

        if trailer_match and date_match:
            confidence = ConfidenceLevel.HIGH
            if doc_trailer and app_trailer:
                reason = f"–¢–° {doc_vehicle} + –ø—Ä–∏—Ü–µ–ø {doc_trailer} + –¥–∞—Ç–∞ {doc_date}"
            else:
                reason = f"–¢–° {doc_vehicle} + –¥–∞—Ç–∞ {doc_date}"
            return (app, confidence, reason)

    return None


def match_by_vehicle_only(
    doc: ParsedDocument,
    applications: List[ApplicationInfo]
) -> Optional[Tuple[ApplicationInfo, ConfidenceLevel, str]]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å –∑–∞—è–≤–∫–æ–π –ø–æ –¢–° + –¥–∞—Ç–∞.

    –ü—Ä–∞–≤–∏–ª–æ 3.1.B: –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ç—è–≥–∞—á–∞ (–±–µ–∑ –ø—Ä–∏—Ü–µ–ø–∞) –∏ –¥–∞—Ç–∞ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ –ø–µ—Ä–∏–æ–¥,
    –∏ –Ω–µ—Ç –¥—Ä—É–≥–æ–π –∑–∞—è–≤–∫–∏ —Å —Ç–µ–º –∂–µ —Ç—è–≥–∞—á–æ–º –≤ —Ç–æ—Ç –∂–µ –ø–µ—Ä–∏–æ–¥.
    """
    if not doc.identifiers.vehicle_plate:
        return None

    doc_vehicle = normalize_vehicle_plate(doc.identifiers.vehicle_plate)
    doc_date = doc.identifiers.document_date

    matching_apps = []

    for app in applications:
        app_vehicle = normalize_vehicle_plate(app.vehicle_plate)

        if doc_vehicle != app_vehicle:
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É
        date_match = False
        if doc_date:
            if app.load_date:
                date_match = dates_match(doc_date, app.load_date, tolerance_days=2)
            elif app.date:
                date_match = dates_match(doc_date, app.date, tolerance_days=5)
            else:
                date_match = True  # –ù–µ—Ç –¥–∞—Ç—ã –≤ –∑–∞—è–≤–∫–µ - —Å—á–∏—Ç–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º

        if date_match:
            matching_apps.append(app)

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–¥–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    if len(matching_apps) == 1:
        app = matching_apps[0]
        return (
            app,
            ConfidenceLevel.HIGH,
            f"–¢–° {doc_vehicle} + –¥–∞—Ç–∞ {doc_date} (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∑–∞—è–≤–∫–∞)"
        )

    return None


def match_by_driver(
    doc: ParsedDocument,
    applications: List[ApplicationInfo]
) -> Optional[Tuple[ApplicationInfo, ConfidenceLevel, str]]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å –∑–∞—è–≤–∫–æ–π –ø–æ –≤–æ–¥–∏—Ç–µ–ª—é + –¥–∞—Ç–∞.

    –ü—Ä–∞–≤–∏–ª–æ 3.1.C: –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤–æ–¥–∏—Ç–µ–ª—è (–§–ò–û) –∏ –¥–∞—Ç–∞ –≤ –ø–µ—Ä–∏–æ–¥–µ –∑–∞—è–≤–∫–∏,
    –∏ –Ω–µ—Ç –¥—Ä—É–≥–æ–π –∑–∞—è–≤–∫–∏ —Å —Ç–µ–º –∂–µ –≤–æ–¥–∏—Ç–µ–ª–µ–º –≤ —Ç–æ—Ç –∂–µ –ø–µ—Ä–∏–æ–¥.
    """
    if not doc.identifiers.driver_name:
        return None

    doc_driver = normalize_driver_name(doc.identifiers.driver_name)
    doc_date = doc.identifiers.document_date

    matching_apps = []

    for app in applications:
        app_driver = normalize_driver_name(app.driver_name)

        if not app_driver:
            continue

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ñ–∞–º–∏–ª–∏–∏ (–ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ)
        doc_surname = doc_driver.split()[0] if doc_driver else ""
        app_surname = app_driver.split()[0] if app_driver else ""

        if doc_surname.lower() != app_surname.lower():
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É
        date_match = False
        if doc_date:
            if app.load_date:
                date_match = dates_match(doc_date, app.load_date, tolerance_days=2)
            elif app.date:
                date_match = dates_match(doc_date, app.date, tolerance_days=5)
            else:
                date_match = True

        if date_match:
            matching_apps.append(app)

    if len(matching_apps) == 1:
        app = matching_apps[0]
        return (
            app,
            ConfidenceLevel.HIGH,
            f"–í–æ–¥–∏—Ç–µ–ª—å {doc_driver} + –¥–∞—Ç–∞ {doc_date}"
        )

    return None


def match_by_document_number(
    doc: ParsedDocument,
    applications: List[ApplicationInfo],
    anchor_matches: Dict[str, ApplicationInfo]
) -> Optional[Tuple[ApplicationInfo, ConfidenceLevel, str]]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ –Ω–æ–º–µ—Ä—É, –µ—Å–ª–∏ —ç—Ç–æ—Ç –Ω–æ–º–µ—Ä —É–∂–µ –±—ã–ª –ø—Ä–∏–≤—è–∑–∞–Ω.

    –ü—Ä–∞–≤–∏–ª–æ 3.1.D: –ù–æ–º–µ—Ä –¢–ù/–¢–¢–ù/–∑–∞–∫–∞–∑–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏ –ø–∞–∫–µ—Ç–∞,
    –≥–¥–µ —É–∂–µ –µ—Å—Ç—å —è–∫–æ—Ä–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç.
    """
    if not doc.identifiers.document_number:
        return None

    doc_num = doc.identifiers.document_number

    if doc_num in anchor_matches:
        app = anchor_matches[doc_num]
        return (
            app,
            ConfidenceLevel.MEDIUM,
            f"–ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_num} —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —è–∫–æ—Ä–Ω—ã–º"
        )

    return None


def match_by_package(
    doc: ParsedDocument,
    doc_index: int,
    all_documents: List[ParsedDocument],
    results: List[MatchResult]
) -> Optional[Tuple[ApplicationInfo, ConfidenceLevel, str]]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –∫ –ø–∞–∫–µ—Ç—É.

    –ü—Ä–∞–≤–∏–ª–æ 4.1: –î–æ–∫—É–º–µ–Ω—Ç –±–µ–∑ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø—Ä–∏–≤—è–∑—ã–≤–∞–µ—Ç—Å—è –∫ —è–∫–æ—Ä–Ω–æ–º—É
    –¥–æ–∫—É–º–µ–Ω—Ç—É, –Ω–∞—Ö–æ–¥—è—â–µ–º—É—Å—è —Ä—è–¥–æ–º.
    """
    # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π —è–∫–æ—Ä–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç (—Å high confidence)
    # –°–Ω–∞—á–∞–ª–∞ —Å–º–æ—Ç—Ä–∏–º –Ω–∞–∑–∞–¥
    for i in range(doc_index - 1, -1, -1):
        if i < len(results) and results[i].is_matched:
            if results[i].confidence == ConfidenceLevel.HIGH:
                return (
                    results[i].application,
                    ConfidenceLevel.LOW,
                    f"–ß–∞—Å—Ç—å –ø–∞–∫–µ—Ç–∞ –ø–æ—Å–ª–µ —è–∫–æ—Ä–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {all_documents[i].doc_type.value} "
                    f"({all_documents[i].page_range})"
                )

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - —Å–º–æ—Ç—Ä–∏–º –≤–ø–µ—Ä—ë–¥
    for i in range(doc_index + 1, len(all_documents)):
        if i < len(results) and results[i].is_matched:
            if results[i].confidence == ConfidenceLevel.HIGH:
                return (
                    results[i].application,
                    ConfidenceLevel.LOW,
                    f"–ß–∞—Å—Ç—å –ø–∞–∫–µ—Ç–∞ –ø–µ—Ä–µ–¥ —è–∫–æ—Ä–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º {all_documents[i].doc_type.value} "
                    f"({all_documents[i].page_range})"
                )

    return None


def match_by_date_and_secondary(
    doc: ParsedDocument,
    applications: List[ApplicationInfo]
) -> Optional[Tuple[ApplicationInfo, ConfidenceLevel, str]]:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ –¥–∞—Ç–µ –∏ –≤—Ç–æ—Ä–∏—á–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º.

    –ü—Ä–∞–≤–∏–ª–æ 4.2: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –µ—Å–ª–∏ –¥—Ä—É–≥–∏–µ –º–µ—Ç–æ–¥—ã –Ω–µ –ø–æ–º–æ–≥–ª–∏.
    """
    doc_date = doc.identifiers.document_date
    if not doc_date:
        return None

    matching_apps = []

    for app in applications:
        date_match = False
        if app.load_date:
            date_match = dates_match(doc_date, app.load_date, tolerance_days=3)
        elif app.date:
            date_match = dates_match(doc_date, app.date, tolerance_days=5)

        if date_match:
            matching_apps.append(app)

    if len(matching_apps) == 1:
        app = matching_apps[0]
        return (
            app,
            ConfidenceLevel.LOW,
            f"–î–∞—Ç–∞ {doc_date} —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –∑–∞—è–≤–∫–æ–π"
        )

    # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π - –ø—Ä–æ–±—É–µ–º –ø–æ –∞–¥—Ä–µ—Å–∞–º
    if len(matching_apps) > 1 and doc.identifiers.loading_address:
        for app in matching_apps:
            if app.route and doc.identifiers.loading_address.lower() in app.route.lower():
                return (
                    app,
                    ConfidenceLevel.LOW,
                    f"–î–∞—Ç–∞ {doc_date} + –∞–¥—Ä–µ—Å —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –º–∞—Ä—à—Ä—É—Ç–æ–º"
                )

    return None


def match_documents_to_applications(
    documents: List[ParsedDocument],
    applications: List[ApplicationInfo]
) -> List[MatchResult]:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∑–∞—è–≤–∫–∞–º–∏.

    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞:
    1. –¢–° + –ø—Ä–∏—Ü–µ–ø + –¥–∞—Ç–∞
    2. –¢–° + –¥–∞—Ç–∞
    3. –í–æ–¥–∏—Ç–µ–ª—å + –¥–∞—Ç–∞
    4. –ù–æ–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–µ—Å–ª–∏ —É–∂–µ –ø—Ä–∏–≤—è–∑–∞–Ω)
    5. –ü–∞–∫–µ—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞
    6. –î–∞—Ç–∞ + –≤—Ç–æ—Ä–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    """
    results: List[MatchResult] = []
    anchor_matches: Dict[str, ApplicationInfo] = {}  # doc_number -> app

    # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Å–∏–ª—å–Ω—ã–µ –ø—Ä–∏–≤—è–∑–∫–∏ (–¢–°, –≤–æ–¥–∏—Ç–µ–ª—å)
    for doc in documents:
        result = MatchResult(document=doc)

        # –ü—Ä–æ–±—É–µ–º –ø–æ –¢–° + –ø—Ä–∏—Ü–µ–ø
        match = match_by_vehicle_and_trailer(doc, applications)
        if match:
            result.application, result.confidence, result.reason_details = match
            result.reason = MatchReason.VEHICLE_TRAILER_DATE
            if doc.identifiers.document_number:
                anchor_matches[doc.identifiers.document_number] = result.application
            results.append(result)
            continue

        # –ü—Ä–æ–±—É–µ–º –ø–æ –¢–°
        match = match_by_vehicle_only(doc, applications)
        if match:
            result.application, result.confidence, result.reason_details = match
            result.reason = MatchReason.VEHICLE_DATE
            if doc.identifiers.document_number:
                anchor_matches[doc.identifiers.document_number] = result.application
            results.append(result)
            continue

        # –ü—Ä–æ–±—É–µ–º –ø–æ –≤–æ–¥–∏—Ç–µ–ª—é
        match = match_by_driver(doc, applications)
        if match:
            result.application, result.confidence, result.reason_details = match
            result.reason = MatchReason.DRIVER_DATE
            if doc.identifiers.document_number:
                anchor_matches[doc.identifiers.document_number] = result.application
            results.append(result)
            continue

        results.append(result)

    # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: –ø—Ä–∏–≤—è–∑–∫–∞ –ø–æ –Ω–æ–º–µ—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞
    for i, result in enumerate(results):
        if result.is_matched:
            continue

        doc = result.document
        match = match_by_document_number(doc, applications, anchor_matches)
        if match:
            result.application, result.confidence, result.reason_details = match
            result.reason = MatchReason.DOCUMENT_NUMBER

    # –¢—Ä–µ—Ç–∏–π –ø—Ä–æ—Ö–æ–¥: –ø–∞–∫–µ—Ç–Ω–∞—è –ª–æ–≥–∏–∫–∞
    for i, result in enumerate(results):
        if result.is_matched:
            continue

        doc = result.document
        match = match_by_package(doc, i, documents, results)
        if match:
            result.application, result.confidence, result.reason_details = match
            result.reason = MatchReason.PACKAGE

    # –ß–µ—Ç–≤—ë—Ä—Ç—ã–π –ø—Ä–æ—Ö–æ–¥: –¥–∞—Ç–∞ + –≤—Ç–æ—Ä–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    for i, result in enumerate(results):
        if result.is_matched:
            continue

        doc = result.document
        match = match_by_date_and_secondary(doc, applications)
        if match:
            result.application, result.confidence, result.reason_details = match
            result.reason = MatchReason.DATE_SECONDARY

    return results


# =============================================================================
# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
# =============================================================================

def process_pdf(
    pdf_path: str,
    applications: List[ApplicationInfo]
) -> MatchingReport:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –∑–∞—è–≤–∫–∞–º–∏.

    Args:
        pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
        applications: –°–ø–∏—Å–æ–∫ –∑–∞—è–≤–æ–∫ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è

    Returns:
        MatchingReport —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
    """
    report = MatchingReport()
    report.source_file = os.path.basename(pdf_path)

    try:
        with pdfplumber.open(pdf_path) as pdf:
            pages = []
            for page in pdf.pages:
                text = page.extract_text() or ""
                pages.append(text)

            report.total_pages = len(pages)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            boundaries = detect_document_boundaries(pages)

            # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç—ã –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            for start, end, doc_type in boundaries:
                doc = ParsedDocument()
                doc.page_start = start
                doc.page_end = end
                doc.doc_type = doc_type
                doc.source_file = report.source_file

                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –¥–æ–∫—É–º–µ–Ω—Ç–∞
                doc_text = "\n".join(pages[start-1:end])
                doc.raw_text = doc_text

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã
                doc.identifiers = extract_identifiers(doc_text, doc_type)

                report.documents.append(doc)

            # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å –∑–∞—è–≤–∫–∞–º–∏
            report.results = match_documents_to_applications(
                report.documents,
                applications
            )

            # –°–æ–±–∏—Ä–∞–µ–º –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ
            report.unmatched_documents = [
                r.document for r in report.results if not r.is_matched
            ]

            if report.unmatched_documents:
                report.warnings.append(
                    f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å {len(report.unmatched_documents)} "
                    f"–¥–æ–∫—É–º–µ–Ω—Ç(–æ–≤)"
                )

    except Exception as e:
        logger.error(f"Error processing PDF {pdf_path}: {e}")
        report.warnings.append(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {e}")

    return report


def format_report(report: MatchingReport) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥."""
    lines = [
        f"=== –û—Ç—á—ë—Ç –æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏: {report.source_file} ===",
        f"–í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {report.total_pages}",
        f"–î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {len(report.documents)}",
        f"–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: {len([r for r in report.results if r.is_matched])}",
        f"–ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: {len(report.unmatched_documents)}",
        ""
    ]

    for result in report.results:
        doc = result.document
        lines.append(f"üìÑ {doc.doc_type.value} ({doc.page_range})")

        if result.is_matched:
            lines.append(f"   ‚úÖ –ó–∞—è–≤–∫–∞: {result.application.number}")
            lines.append(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence.value}")
            lines.append(f"   –û—Å–Ω–æ–≤–∞–Ω–∏–µ: {result.reason_details}")
        else:
            lines.append(f"   ‚ùå –ù–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω")

        if doc.identifiers.vehicle_plate:
            lines.append(f"   –¢–°: {doc.identifiers.vehicle_plate}")
        if doc.identifiers.trailer_plate:
            lines.append(f"   –ü—Ä–∏—Ü–µ–ø: {doc.identifiers.trailer_plate}")
        if doc.identifiers.driver_name:
            lines.append(f"   –í–æ–¥–∏—Ç–µ–ª—å: {doc.identifiers.driver_name}")
        if doc.identifiers.document_date:
            lines.append(f"   –î–∞—Ç–∞: {doc.identifiers.document_date}")

        lines.append("")

    if report.warnings:
        lines.append("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è:")
        for warning in report.warnings:
            lines.append(f"   - {warning}")

    return "\n".join(lines)


# =============================================================================
# CLI –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
# =============================================================================

if __name__ == "__main__":
    import sys

    logging.basicConfig(level=logging.INFO)

    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python document_matcher.py <pdf_file> [--apps <apps_json>]")
        sys.exit(1)

    pdf_path = sys.argv[1]

    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞—è–≤–∫–∏ (–µ—Å–ª–∏ –Ω–µ —É–∫–∞–∑–∞–Ω —Ñ–∞–π–ª)
    test_applications = [
        ApplicationInfo(
            number="–°–ü139948/1",
            date="16.06.2025",
            vehicle_plate="–¢461–†–ù196",
            trailer_plate="–í–ú228766",
            driver_name="–ë–æ–≥–¥–∞–Ω–æ–≤ –°–µ—Ä–≥–µ–π –í–∞–ª–µ—Ä—å–µ–≤–∏—á",
            load_date="16.06.2025"
        ),
        ApplicationInfo(
            number="–°–ü144280/1",
            date="18.06.2025",
            vehicle_plate="–°805–†–•196",
            trailer_plate="–ï–ê707566",
            driver_name="–ó–∞–π—Ü–µ–≤ –Æ—Ä–∏–π –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–∏—á",
            load_date="19.06.2025"
        ),
    ]

    report = process_pdf(pdf_path, test_applications)
    print(format_report(report))
